{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/da-roth/NeuronalNetworkTensorflowFramework/blob/main/multilevelmontecarlolearning/introductory_example_single.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BtTim4HwVYa",
        "outputId": "ce07207c-4b82-4bb0-f8e8-45a264b0619b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\DanielPrivateGitHub\\Documents\\GitHub\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "WARNING:tensorflow:From c:\\Users\\DanielPrivateGitHub\\Documents\\GitHub\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:561: calling function (from tensorflow.python.eager.def_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
            "0\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\DanielPrivateGitHub\\Documents\\GitHub\\NeuronalNetworkTensorflowFramework\\multilevelmontecarlolearning\\introductory_example_single.ipynb Cell 2\u001b[0m in \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/DanielPrivateGitHub/Documents/GitHub/NeuronalNetworkTensorflowFramework/multilevelmontecarlolearning/introductory_example_single.ipynb#W1sZmlsZQ%3D%3D?line=232'>233</a>\u001b[0m u_mc_test \u001b[39m=\u001b[39m u \u001b[39m/\u001b[39m tf\u001b[39m.\u001b[39mcast(N_l, tf\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/DanielPrivateGitHub/Documents/GitHub/NeuronalNetworkTensorflowFramework/multilevelmontecarlolearning/introductory_example_single.ipynb#W1sZmlsZQ%3D%3D?line=234'>235</a>\u001b[0m \u001b[39m#Start training and testing                       \u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/DanielPrivateGitHub/Documents/GitHub/NeuronalNetworkTensorflowFramework/multilevelmontecarlolearning/introductory_example_single.ipynb#W1sZmlsZQ%3D%3D?line=235'>236</a>\u001b[0m train_and_test(xi, xi_approx, xi, u_mc_test, u_reference,neurons, train_steps,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/DanielPrivateGitHub/Documents/GitHub/NeuronalNetworkTensorflowFramework/multilevelmontecarlolearning/introductory_example_single.ipynb#W1sZmlsZQ%3D%3D?line=236'>237</a>\u001b[0m                         mc_rounds, mc_freq, \u001b[39m'\u001b[39;49m\u001b[39msingle-introductory.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, dtype)   \n",
            "\u001b[1;32mc:\\Users\\DanielPrivateGitHub\\Documents\\GitHub\\NeuronalNetworkTensorflowFramework\\multilevelmontecarlolearning\\introductory_example_single.ipynb Cell 2\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/DanielPrivateGitHub/Documents/GitHub/NeuronalNetworkTensorflowFramework/multilevelmontecarlolearning/introductory_example_single.ipynb#W1sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m     _approximate_errors()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/DanielPrivateGitHub/Documents/GitHub/NeuronalNetworkTensorflowFramework/multilevelmontecarlolearning/introductory_example_single.ipynb#W1sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m     t0_train \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/DanielPrivateGitHub/Documents/GitHub/NeuronalNetworkTensorflowFramework/multilevelmontecarlolearning/introductory_example_single.ipynb#W1sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m   sess\u001b[39m.\u001b[39;49mrun(train_op, feed_dict\u001b[39m=\u001b[39;49m{is_training:\u001b[39mTrue\u001b[39;49;00m})\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/DanielPrivateGitHub/Documents/GitHub/NeuronalNetworkTensorflowFramework/multilevelmontecarlolearning/introductory_example_single.ipynb#W1sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m t1_train \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/DanielPrivateGitHub/Documents/GitHub/NeuronalNetworkTensorflowFramework/multilevelmontecarlolearning/introductory_example_single.ipynb#W1sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m _approximate_errors()\n",
            "File \u001b[1;32mc:\\Users\\DanielPrivateGitHub\\Documents\\GitHub\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\client\\session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 968\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[0;32m    969\u001b[0m                      run_metadata_ptr)\n\u001b[0;32m    970\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[0;32m    971\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
            "File \u001b[1;32mc:\\Users\\DanielPrivateGitHub\\Documents\\GitHub\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[39m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[39m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m \u001b[39mif\u001b[39;00m final_fetches \u001b[39mor\u001b[39;00m final_targets \u001b[39mor\u001b[39;00m (handle \u001b[39mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1191\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_run(handle, final_targets, final_fetches,\n\u001b[0;32m   1192\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m   results \u001b[39m=\u001b[39m []\n",
            "File \u001b[1;32mc:\\Users\\DanielPrivateGitHub\\Documents\\GitHub\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1368\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[0;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1371\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m   1372\u001b[0m                        run_metadata)\n\u001b[0;32m   1373\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
            "File \u001b[1;32mc:\\Users\\DanielPrivateGitHub\\Documents\\GitHub\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_call\u001b[39m(\u001b[39mself\u001b[39m, fn, \u001b[39m*\u001b[39margs):\n\u001b[0;32m   1377\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m   1379\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1380\u001b[0m     message \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_text(e\u001b[39m.\u001b[39mmessage)\n",
            "File \u001b[1;32mc:\\Users\\DanielPrivateGitHub\\Documents\\GitHub\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[0;32m   1359\u001b[0m   \u001b[39m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[0;32m   1360\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_graph()\n\u001b[1;32m-> 1361\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m   1362\u001b[0m                                   target_list, run_metadata)\n",
            "File \u001b[1;32mc:\\Users\\DanielPrivateGitHub\\Documents\\GitHub\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_tf_sessionrun\u001b[39m(\u001b[39mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1453\u001b[0m                         run_metadata):\n\u001b[1;32m-> 1454\u001b[0m   \u001b[39mreturn\u001b[39;00m tf_session\u001b[39m.\u001b[39;49mTF_SessionRun_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session, options, feed_dict,\n\u001b[0;32m   1455\u001b[0m                                           fetch_list, target_list,\n\u001b[0;32m   1456\u001b[0m                                           run_metadata)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Single-level algorithm using the Milstein scheme\n",
        "#For more detailed explanations of the training and model parameters\n",
        "#see Gerstner et al. \"Multilevel Monte Carlo learning.\" arXiv preprint arXiv:2102.08734 (2021).\n",
        "\n",
        "#Packages\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt \n",
        "import tensorflow_probability as tfp\n",
        "import time\n",
        "from tensorflow.python.ops import init_ops\n",
        "from tensorflow.python.training.moving_averages import assign_moving_average\n",
        "\n",
        "#Basic network framework according to Beck, Christian, et al. \"Solving the Kolmogorov PDE by means of deep learning.\" Journal of Scientific Computing 88.3 (2021): 1-28.\n",
        "def neural_net(x, xi_approx, neurons, is_training, name,\n",
        "                    mv_decay=0.9, dtype=tf.float32):\n",
        "  \n",
        "  def approx_test(): return xi_approx\n",
        "  def approx_learn(): return x\n",
        "  x = tf.cond(is_training, approx_learn,approx_test)\n",
        "\n",
        "  def _batch_normalization(_x):\n",
        "    beta = tf.get_variable('beta', [_x.get_shape()[-1]],\n",
        "                           dtype, init_ops.zeros_initializer())\n",
        "    gamma = tf.get_variable('gamma', [_x.get_shape()[-1]],\n",
        "                            dtype, init_ops.ones_initializer())\n",
        "    mv_mean = tf.get_variable('mv_mean', [_x.get_shape()[-1]],\n",
        "                              dtype, init_ops.zeros_initializer(),\n",
        "                              trainable=False)\n",
        "    mv_variance = tf.get_variable('mv_variance', [_x.get_shape()[-1]],\n",
        "                                  dtype, init_ops.ones_initializer(),\n",
        "                                  trainable=False)\n",
        "    mean, variance = tf.nn.moments(_x, [0], name='moments')\n",
        "    tf.add_to_collection(tf.GraphKeys.UPDATE_OPS,\n",
        "                         assign_moving_average(mv_mean, mean,\n",
        "                                               mv_decay, True))\n",
        "    tf.add_to_collection(tf.GraphKeys.UPDATE_OPS,\n",
        "                         assign_moving_average(mv_variance, variance,\n",
        "                                               mv_decay, False))\n",
        "    mean, variance = tf.cond(is_training,\n",
        "                             lambda: (mean, variance),\n",
        "                             lambda: (mv_mean, mv_variance))\n",
        "    return tf.nn.batch_normalization(_x, mean, variance,\n",
        "                                     beta, gamma, 1e-6)\n",
        "  \n",
        "  def _layer(_x, out_size, activation_fn):\n",
        "    w = tf.get_variable('weights',\n",
        "                        [_x.get_shape().as_list()[-1], out_size],\n",
        "                        dtype, tf.initializers.glorot_uniform())\n",
        "    return activation_fn(_batch_normalization(tf.matmul(_x, w)))\n",
        "  \n",
        "  with tf.variable_scope(name):\n",
        "      x = _batch_normalization(x)\n",
        "      for i in range(len(neurons)):\n",
        "        with tf.variable_scope('layer_%i_' % (i + 1)):\n",
        "          x = _layer(x, neurons[i],\n",
        "            tf.nn.tanh if i < len(neurons)-1 else tf.identity)\n",
        "  return x\n",
        "\n",
        "#Basic network framework according to Beck, Christian, et al. \"Solving the Kolmogorov PDE by means of deep learning.\" Journal of Scientific Computing 88.3 (2021): 1-28.\n",
        "#Minor adjustments to file output and in lines 108-115 changed to exponential decay\n",
        "\n",
        "def train_and_test(xi, xi_approx, x_sde, phi, u_reference, neurons,\n",
        "          train_steps,mc_rounds, mc_freq, file_name,\n",
        "          dtype=tf.float32):\n",
        "  \n",
        "  def _approximate_errors():\n",
        "    lr, gs = sess.run([learning_rate, global_step])\n",
        "    l1_err, l2_err, li_err = 0., 0., 0.\n",
        "    rel_l1_err, rel_l2_err, rel_li_err = 0., 0., 0.\n",
        "    for _ in range(mc_rounds):\n",
        "      plot_xi, plot_approx, plot_ref, l1, l2, li, rl1, rl2, rli, appr, ref \\\n",
        "              = sess.run([xi_approx, u_approx,u_reference,err_l_1, err_l_2, err_l_inf,\n",
        "                          rel_err_l_1, rel_err_l_2, rel_err_l_inf, approx, reference],\n",
        "                         feed_dict={is_training: False})\n",
        "      l1_err, l2_err, li_err = (l1_err + l1, l2_err + l2,\n",
        "                                  np.maximum(li_err, li))\n",
        "      rel_l1_err, rel_l2_err, rel_li_err \\\n",
        "              = (rel_l1_err + rl1, rel_l2_err + rl2,\n",
        "                 np.maximum(rel_li_err, rli))\n",
        "    l1_err, l2_err = l1_err / mc_rounds, np.sqrt(l2_err / mc_rounds)\n",
        "    rel_l1_err, rel_l2_err \\\n",
        "              = rel_l1_err / mc_rounds, np.sqrt(rel_l2_err / mc_rounds)\n",
        "    t_mc = time.time()\n",
        "\n",
        "    file_out.write('%i, %f, %f, %f, %f \\n' % (gs, li_err, lr, t1_train - t0_train, t_mc - t1_train)) \n",
        "    file_out.flush()\n",
        "    \n",
        "\n",
        "  t0_train = time.time()\n",
        "  is_training = tf.placeholder(tf.bool, [])\n",
        "  u_approx = neural_net(xi, xi_approx, neurons, is_training, 'u_approx', dtype=dtype)  \n",
        "  loss = tf.reduce_mean(tf.squared_difference(u_approx, phi))\n",
        "  \n",
        "  approx=tf.reduce_mean(u_approx)\n",
        "  reference=tf.reduce_mean(u_reference)\n",
        "  err = tf.abs(u_approx - u_reference)\n",
        "  err_l_1 = tf.reduce_mean(err)\n",
        "  err_l_2 = tf.reduce_mean(err ** 2)\n",
        "  err_l_inf = tf.reduce_max(err)\n",
        "  rel_err = err / tf.maximum(u_reference, 1e-4)\n",
        "  rel_err_l_1 = tf.reduce_mean(rel_err)\n",
        "  rel_err_l_2 = tf.reduce_mean(rel_err ** 2)\n",
        "  rel_err_l_inf = tf.reduce_max(rel_err)\n",
        "\n",
        "  lr=0.01\n",
        "  step_rate = 40000\n",
        "  decay = 0.1\n",
        "\n",
        "  global_step = tf.Variable(0, trainable=False)\n",
        "  increment_global_step = tf.assign(global_step, global_step + 1)\n",
        "  learning_rate = tf.train.exponential_decay(lr, global_step, step_rate, decay, staircase=True)\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, epsilon=0.01)\n",
        "\n",
        "\n",
        "  update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, 'u_approx')\n",
        "  with tf.control_dependencies(update_ops):\n",
        "    train_op = optimizer.minimize(loss, global_step)\n",
        "    \n",
        "        \n",
        "  file_out = open(file_name, 'w')\n",
        "  file_out.write('step, li_err, learning_rate, time_train, time_test \\n ')\n",
        "    \n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "        \n",
        "    for step in range(train_steps):\n",
        "      if step % mc_freq == 0:\n",
        "        print(step)\n",
        "        t1_train = time.time()\n",
        "        _approximate_errors()\n",
        "        t0_train = time.time()\n",
        "      sess.run(train_op, feed_dict={is_training:True})\n",
        "    t1_train = time.time()\n",
        "    _approximate_errors()\n",
        "        \n",
        "  file_out.close()\n",
        "  \n",
        "#Model and training parameter specification\n",
        "for i in range(1,2):\n",
        "  tf.reset_default_graph()\n",
        "  tf.random.set_random_seed(i)\n",
        "  with tf.Session()  as sess:\n",
        "    dtype = tf.float32\n",
        "\n",
        "    #Set network and training parameter\n",
        "    batch_size =125000\n",
        "    batch_size_approx=batch_size\n",
        "    N, d = 128, 5\n",
        "    neurons = [50, 50, 1]\n",
        "    train_steps = 150000\n",
        "    mc_rounds, mc_freq = 100, 5000\n",
        "    mc_samples_ref, mc_rounds_ref = 1, 1\n",
        "    N_l=1\n",
        "\n",
        "    #Define training and test interval\n",
        "    s_0_l=80.0\n",
        "    s_0_r=120.0\n",
        "    sigma_l=0.1\n",
        "    sigma_r=0.2\n",
        "    mu_l=0.02\n",
        "    mu_r=0.05\n",
        "    T_l=0.9\n",
        "    T_r=1.0\n",
        "    K_l=109.0\n",
        "    K_r=110.0\n",
        "    s_0_l_approx=80.4\n",
        "    s_0_r_approx=119.6\n",
        "    sigma_l_approx=0.11\n",
        "    sigma_r_approx=0.19\n",
        "    mu_l_approx=0.03\n",
        "    mu_r_approx=0.04\n",
        "    T_l_approx=0.91\n",
        "    T_r_approx=0.99\n",
        "    K_l_approx=109.1\n",
        "    K_r_approx=109.9\n",
        "    s0 = tf.random_uniform((batch_size,1), minval=s_0_l,\n",
        "                                 maxval=s_0_r, dtype=dtype)\n",
        "    sigma=tf.random_uniform((batch_size,1),\n",
        "                            minval=sigma_l,maxval=sigma_r, dtype=dtype)\n",
        "    mu=tf.random_uniform((batch_size,1),\n",
        "                            minval=mu_l,maxval=mu_r, dtype=dtype)\n",
        "    T=tf.random_uniform((batch_size,1),\n",
        "                            minval=T_l,maxval=T_r, dtype=dtype)\n",
        "    K=tf.random_uniform((batch_size,1),\n",
        "                      minval=K_l,maxval=K_r, dtype=dtype)\n",
        "    s0_approx = tf.random_uniform((batch_size_approx,  1 ), \n",
        "                            minval=s_0_l_approx,maxval=s_0_r_approx, dtype=dtype)\n",
        "    sigma_approx=tf.random_uniform((batch_size_approx,  1 ), \n",
        "                            minval=sigma_l_approx,maxval=sigma_r_approx, dtype=dtype)\n",
        "    mu_approx=tf.random_uniform((batch_size_approx,1),\n",
        "                            minval=mu_l_approx,maxval=mu_r_approx, dtype=dtype)\n",
        "    T_approx=tf.random_uniform((batch_size_approx,1),\n",
        "                            minval=T_l_approx,maxval=T_r_approx, dtype=dtype)\n",
        "    K_approx=tf.random_uniform((batch_size_approx,1),\n",
        "                            minval=K_l_approx,maxval=K_r_approx, dtype=dtype)\n",
        "    \n",
        "    xi=tf.reshape(tf.stack([s0,sigma,mu,T,K], axis=2), (batch_size,d))\n",
        "    xi_approx=tf.reshape(tf.stack([s0_approx,sigma_approx,mu_approx,T_approx,K_approx], axis=2), (batch_size_approx,d))\n",
        "    \n",
        "    #Closed solution as reference\n",
        "    tfd = tfp.distributions\n",
        "    dist = tfd.Normal(loc=tf.cast(0.,tf.float32), scale=tf.cast(1.,tf.float32))\n",
        "    d1=tf.math.divide(\n",
        "    (tf.log(tf.math.divide(s0_approx,K_approx))+(mu_approx + 0.5*sigma_approx**2)*T_approx) , (sigma_approx*tf.sqrt(T_approx)))\n",
        "    d2=tf.math.divide(\n",
        "    (tf.log(tf.math.divide(s0_approx,K_approx))+(mu_approx - 0.5*sigma_approx**2)*T_approx) , (sigma_approx*tf.sqrt(T_approx)))\n",
        "    u_reference= tf.multiply(s0_approx,(dist.cdf(d1)))-K_approx*tf.exp(-mu_approx*T_approx)*(dist.cdf(d2))\n",
        "\n",
        "  #European option\n",
        "  def phi(x,sigma,mu,T,K, axis=1):\n",
        "    payoffcoarse=tf.exp(-mu * T)* tf.maximum(x - K, 0.)\n",
        "    return payoffcoarse\n",
        "  #Milstein scheme\n",
        "  def sde_body(idx, s, sigma,mu,T,K, samples): \n",
        "    h=T/N\n",
        "    z=tf.random_normal(shape=(samples, batch_size,1),\n",
        "                          stddev=1., dtype=dtype)\n",
        "    s=s + mu *s * h +sigma * s *tf.sqrt(h)*z + 0.5 *sigma *s *sigma * ((tf.sqrt(h)*z)**2-h)    \n",
        "    return tf.add(idx, 1), s, sigma,mu,T,K\n",
        "  #Monte Carlo loop                 \n",
        "  def mc_body(idx, p):\n",
        "    _, _x, _sigma,_mu,_T,_K = tf.while_loop(lambda _idx, s, sigma,mu,T,K: _idx < N,\n",
        "                          lambda _idx, s, sigma,mu,T,K: sde_body(_idx, s, sigma,mu,T,K,\n",
        "                                                   mc_samples_ref),\n",
        "                                                   loop_var_mc)\n",
        "    return idx + 1, p + tf.reduce_mean(phi(_x,_sigma,_mu,_T,_K, 2), axis=0)\n",
        "\n",
        "  loop_var_mc = (tf.constant(0),tf.ones((mc_samples_ref,batch_size, 1), dtype) * s0, tf.ones((mc_samples_ref,batch_size, 1), dtype) * sigma,tf.ones((mc_samples_ref,batch_size, 1), dtype) * mu,tf.ones((mc_samples_ref,batch_size, 1), dtype) * T,tf.ones((mc_samples_ref,batch_size, 1), dtype) * K)\n",
        "  _, u = tf.while_loop(lambda idx, p: idx < N_l, mc_body,(tf.constant(0), tf.zeros((batch_size, 1), dtype)))\n",
        "  u_mc_test = u / tf.cast(N_l, tf.float32)\n",
        "\n",
        "  #Start training and testing                       \n",
        "  train_and_test(xi, xi_approx, xi, u_mc_test, u_reference,neurons, train_steps,\n",
        "                          mc_rounds, mc_freq, 'single-introductory.csv', dtype)   \n",
        "\n",
        "                        \n",
        "                        \n",
        "                       "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNfnBAP+9N3OJr+i+X5YuFB",
      "include_colab_link": true,
      "name": "introductory-example-single.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
