{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version = 2.10.0\n",
      "TF version = 2.10.0\n",
      "TF version = 2.10.0\n",
      "TF version = 2.10.0\n",
      "Neural network initialized with the following settings:\n",
      "Neurons per layer: 20\n",
      "Amount of hidden layers: 2\n",
      "Activations functions: <function tanh at 0x0000029D731F0DC0>\n",
      "Training will be done with the following settings:\n",
      "\n",
      "min_batch_size: 20\n",
      "batches per epoch: 10000\n",
      "Hence, used batch_size will be: 20\n",
      "epochs: 1\n",
      "learning_rate_schedule: [(0.0, 0.01), (0.2, 0.001), (0.4, 0.0001), (0.6, 1e-05), (0.8, 1e-06)]\n",
      "\n",
      " Train started:\n",
      "Training done.\n",
      "Training will be done with the following settings:\n",
      "\n",
      "min_batch_size: 20\n",
      "batches per epoch: 10000\n",
      "Hence, used batch_size will be: 20\n",
      "epochs: 1\n",
      "learning_rate_schedule: [(0.0, 0.01), (0.2, 0.001), (0.4, 0.0001), (0.6, 1e-05), (0.8, 1e-06)]\n",
      "\n",
      " Train started:\n",
      "Training done.\n",
      "Training will be done with the following settings:\n",
      "\n",
      "min_batch_size: 20\n",
      "batches per epoch: 10000\n",
      "Hence, used batch_size will be: 20\n",
      "epochs: 1\n",
      "learning_rate_schedule: [(0.0, 0.01), (0.2, 0.001), (0.4, 0.0001), (0.6, 1e-05), (0.8, 1e-06)]\n",
      "\n",
      " Train started:\n",
      "Training done.\n",
      "Training will be done with the following settings:\n",
      "\n",
      "min_batch_size: 20\n",
      "batches per epoch: 10000\n",
      "Hence, used batch_size will be: 20\n",
      "epochs: 1\n",
      "learning_rate_schedule: [(0.0, 0.01), (0.2, 0.001), (0.4, 0.0001), (0.6, 1e-05), (0.8, 1e-06)]\n",
      "\n",
      " Train started:\n",
      "Training done.\n",
      "Training will be done with the following settings:\n",
      "\n",
      "min_batch_size: 20\n",
      "batches per epoch: 10000\n",
      "Hence, used batch_size will be: 20\n",
      "epochs: 1\n",
      "learning_rate_schedule: [(0.0, 0.01), (0.2, 0.001), (0.4, 0.0001), (0.6, 1e-05), (0.8, 1e-06)]\n",
      "\n",
      " Train started:\n",
      "Training done.\n",
      "Training will be done with the following settings:\n",
      "\n",
      "min_batch_size: 20\n",
      "batches per epoch: 10000\n",
      "Hence, used batch_size will be: 20\n",
      "epochs: 1\n",
      "learning_rate_schedule: [(0.0, 0.01), (0.2, 0.001), (0.4, 0.0001), (0.6, 1e-05), (0.8, 1e-06)]\n",
      "\n",
      " Train started:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 37\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39m### 3. Train network\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[0;32m     35\u001b[0m trainingMethod \u001b[39m=\u001b[39m TrainingMethod\u001b[39m.\u001b[39mGenerateDataDuringTraining\n\u001b[1;32m---> 37\u001b[0m xTest, yTest, yPredicted \u001b[39m=\u001b[39m train_and_test(generator, sizes, nTest, dataSeed, \u001b[39mNone\u001b[39;49;00m, weightSeed, hiddenNeurons, hiddenLayers, activationFunctions, trainingMethod, batches_per_epoch \u001b[39m=\u001b[39;49m batches_per_epoch)\n\u001b[0;32m     39\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m### 3. Study results\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m###   \u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m \u001b[39m# show predicitions\u001b[39;00m\n\u001b[0;32m     44\u001b[0m plot_results(\u001b[39m\"\u001b[39m\u001b[39mCDF random inputs\u001b[39m\u001b[39m\"\u001b[39m, yPredicted, xTest, \u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mCDF(x)\u001b[39m\u001b[39m\"\u001b[39m, yTest, sizes, \u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m, trainingMethod)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\src\\NNFramework\\train_and_test.py:91\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[1;34m(generator, sizes, nTest, dataSeed, testSeed, weightSeed, hiddenNeurons, hiddenLayers, activationFunctions, trainingMethod, testFrequency, outputDimension, deltidx, epochs, learning_rate_schedule, batches_per_epoch, min_batch_size)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39m# 4. Train network\u001b[39;00m\n\u001b[0;32m     90\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> 91\u001b[0m regressor\u001b[39m.\u001b[39;49mtrain(\u001b[39m\"\u001b[39;49m\u001b[39mstandard training\u001b[39;49m\u001b[39m\"\u001b[39;49m,epochs,learning_rate_schedule,batches_per_epoch,min_batch_size)\n\u001b[0;32m     92\u001b[0m t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m testFrequency \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\src\\NNFramework\\Neural_Approximator.py:173\u001b[0m, in \u001b[0;36mNeural_Approximator.train\u001b[1;34m(self, description, epochs, learning_rate_schedule, batches_per_epoch, min_batch_size, reinit, callback, callback_epochs, xTest, yTest)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m,            \n\u001b[0;32m    157\u001b[0m           description,\n\u001b[0;32m    158\u001b[0m           \u001b[39m# training params\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m           yTest\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m              \n\u001b[0;32m    171\u001b[0m           ):     \u001b[39m# call after what epochs, e.g. [5, 20]\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m     train(description, \n\u001b[0;32m    174\u001b[0m           \u001b[39mself\u001b[39;49m, \n\u001b[0;32m    175\u001b[0m           epochs, \n\u001b[0;32m    176\u001b[0m           learning_rate_schedule, \n\u001b[0;32m    177\u001b[0m           batches_per_epoch, \n\u001b[0;32m    178\u001b[0m           min_batch_size,\n\u001b[0;32m    179\u001b[0m           reinit, \n\u001b[0;32m    180\u001b[0m           callback, \n\u001b[0;32m    181\u001b[0m           callback_epochs,\n\u001b[0;32m    182\u001b[0m           xTest,\n\u001b[0;32m    183\u001b[0m           yTest)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\src\\NNFramework\\train.py:59\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(description, approximator, epochs, learning_rate_schedule, batches_per_epoch, min_batch_size, reinit, callback, callback_epochs, xTest, yTest)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m# train one epoch\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m approximator\u001b[39m.\u001b[39mdifferential:\n\u001b[1;32m---> 59\u001b[0m     vanilla_train_one_epoch(\n\u001b[0;32m     60\u001b[0m         approximator\u001b[39m.\u001b[39;49minputs, \n\u001b[0;32m     61\u001b[0m         approximator\u001b[39m.\u001b[39;49mlabels, \n\u001b[0;32m     62\u001b[0m         approximator\u001b[39m.\u001b[39;49mlearning_rate, \n\u001b[0;32m     63\u001b[0m         approximator\u001b[39m.\u001b[39;49mminimizer, \n\u001b[0;32m     64\u001b[0m         approximator\u001b[39m.\u001b[39;49mx, \n\u001b[0;32m     65\u001b[0m         approximator\u001b[39m.\u001b[39;49my, \n\u001b[0;32m     66\u001b[0m         learning_rate, \n\u001b[0;32m     67\u001b[0m         batch_size, \n\u001b[0;32m     68\u001b[0m         approximator\u001b[39m.\u001b[39;49msession)\n\u001b[0;32m     69\u001b[0m     i \u001b[39m=\u001b[39m i \u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     70\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m testFrequency \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     71\u001b[0m         \u001b[39m#print('learning_rate for the last epoch was' + str(learning_rate))\u001b[39;00m\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\src\\NNFramework\\vanilla_train_one_epoch.py:15\u001b[0m, in \u001b[0;36mvanilla_train_one_epoch\u001b[1;34m(inputs, labels, lr_placeholder, minimizer, x_train, y_train, learning_rate, batch_size, session)\u001b[0m\n\u001b[0;32m     13\u001b[0m last \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(batch_size, m) \u001b[39m#Assume batch size is 256, than first index = 0, after one loop first is at 256. If last is 750 (again index) we will ahve 3 iterations in while\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39mwhile\u001b[39;00m first \u001b[39m<\u001b[39m m:\n\u001b[1;32m---> 15\u001b[0m     session\u001b[39m.\u001b[39;49mrun(minimizer, feed_dict \u001b[39m=\u001b[39;49m {\n\u001b[0;32m     16\u001b[0m         inputs: x_train[first:last], \n\u001b[0;32m     17\u001b[0m         labels: y_train[first:last],\n\u001b[0;32m     18\u001b[0m         lr_placeholder: learning_rate\n\u001b[0;32m     19\u001b[0m     })\n\u001b[0;32m     20\u001b[0m     first \u001b[39m=\u001b[39m last\n\u001b[0;32m     21\u001b[0m     last \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(first \u001b[39m+\u001b[39m batch_size, m)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\client\\session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 968\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[0;32m    969\u001b[0m                      run_metadata_ptr)\n\u001b[0;32m    970\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[0;32m    971\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[39m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[39m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m \u001b[39mif\u001b[39;00m final_fetches \u001b[39mor\u001b[39;00m final_targets \u001b[39mor\u001b[39;00m (handle \u001b[39mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1191\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_run(handle, final_targets, final_fetches,\n\u001b[0;32m   1192\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m   results \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1368\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[0;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1371\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m   1372\u001b[0m                        run_metadata)\n\u001b[0;32m   1373\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_call\u001b[39m(\u001b[39mself\u001b[39m, fn, \u001b[39m*\u001b[39margs):\n\u001b[0;32m   1377\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m   1379\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1380\u001b[0m     message \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_text(e\u001b[39m.\u001b[39mmessage)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[0;32m   1359\u001b[0m   \u001b[39m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[0;32m   1360\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_graph()\n\u001b[1;32m-> 1361\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m   1362\u001b[0m                                   target_list, run_metadata)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_tf_sessionrun\u001b[39m(\u001b[39mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1453\u001b[0m                         run_metadata):\n\u001b[1;32m-> 1454\u001b[0m   \u001b[39mreturn\u001b[39;00m tf_session\u001b[39m.\u001b[39;49mTF_SessionRun_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session, options, feed_dict,\n\u001b[0;32m   1455\u001b[0m                                           fetch_list, target_list,\n\u001b[0;32m   1456\u001b[0m                                           run_metadata)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Copy of Main.py as a juypter notebook to visualize results\n",
    "\n",
    "###\n",
    "### 0. Import packages and references\n",
    "###\n",
    "### Import framework\n",
    "import os\n",
    "mainDirectory = os.path.abspath(os.path.join(os.getcwd() , '..','..', '..','..'))\n",
    "packageFile = os.path.abspath(os.path.join(mainDirectory,'src', 'NNFramework', 'packages.py'))\n",
    "exec(open(packageFile).read())\n",
    "### - dataSeed = seed for simulations or (for csv input) for randomization of csv\n",
    "dataSeed = 1 \n",
    "weightSeed = 1 \n",
    "\n",
    "###\n",
    "### 1. Training data\n",
    "###\n",
    "\n",
    "generator = CDF()\n",
    "sizes = [10000,100] # [sizePerTrainingStep, trainingSteps]\n",
    "nTest = 2000 # Test set size\n",
    "\n",
    "\n",
    "###\n",
    "### 2. Set Nueral network structure / Hyperparameters\n",
    "### \n",
    "\n",
    "hiddenNeurons = 20              # we use equal neurons for each hidden layer\n",
    "hiddenLayers = 2                 # amount of hidden layers\n",
    "activationFunctions = tf.nn.tanh    # activation functions of hidden layers\n",
    "\n",
    "batches_per_epoch = sizes[0]\n",
    "###\n",
    "### 3. Train network\n",
    "###\n",
    "trainingMethod = TrainingMethod.GenerateDataDuringTraining\n",
    "\n",
    "xTest, yTest, yPredicted = train_and_test(generator, sizes, nTest, dataSeed, None, weightSeed, hiddenNeurons, hiddenLayers, activationFunctions, trainingMethod, batches_per_epoch = batches_per_epoch)\n",
    "    \n",
    "###\n",
    "### 3. Study results\n",
    "###   \n",
    "\n",
    "# show predicitions\n",
    "plot_results(\"CDF random inputs\", yPredicted, xTest, \"x\", \"CDF(x)\", yTest, sizes, True, False, None, trainingMethod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\dev\\\\NeuronalNetworkTensorflowFramework\\\\src\\\\Examples\\\\CumulativeDensitiyFunction\\\\4. CDF_onFly'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.abspath('.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83a8566224840326395a21c083192bd4c5adbde2ed4f12bcb51b671fb460c3a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
