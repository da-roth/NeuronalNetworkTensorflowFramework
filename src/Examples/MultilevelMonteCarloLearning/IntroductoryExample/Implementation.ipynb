{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU support =  False\n",
      "RMSE after 100 training steps is [1.54332267]\n",
      "RMSE after 200 training steps is [0.2092614]\n",
      "RMSE after 300 training steps is [0.22053094]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\src\\Examples\\MultilevelMonteCarloLearning\\IntroductoryExample\\Implementation.ipynb Cell 1\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m TrainSettings\u001b[39m.\u001b[39mset_trainingSteps(\u001b[39m5000\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m### 3. Train network and Study results\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m### Comment: For different trainingSetSizes the neural network reset and not saved, hence train and evaluation of yPredicted are done together currently\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m xTest, yTest, yPredicted \u001b[39m=\u001b[39m train_and_test(Generator, Regressor, TrainSettings)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m plot_results(\u001b[39m\"\u001b[39m\u001b[39mpredicted vs. expected\u001b[39m\u001b[39m\"\u001b[39m, yPredicted, xTest, yTest, Generator)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\montecarlolearning\\train_and_test.py:98\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[1;34m(Generator, Regressor, TrainSettings)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39m# 4. Train network\u001b[39;00m\n\u001b[0;32m     97\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> 98\u001b[0m Regressor\u001b[39m.\u001b[39;49mtrain(\u001b[39m\"\u001b[39;49m\u001b[39mstandard training\u001b[39;49m\u001b[39m\"\u001b[39;49m,TrainSettings, reinit \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     99\u001b[0m t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    101\u001b[0m \u001b[39m# Generate output file and print results during training\u001b[39;00m\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\montecarlolearning\\Neural_Approximator.py:221\u001b[0m, in \u001b[0;36mNeural_Approximator.train\u001b[1;34m(self, description, TrainingSettings, reinit, callback, callback_epochs, xTest, yTest)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m,            \n\u001b[0;32m    210\u001b[0m           description,\n\u001b[0;32m    211\u001b[0m           TrainingSettings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    218\u001b[0m           yTest\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m              \n\u001b[0;32m    219\u001b[0m           ):     \u001b[39m# call after what epochs, e.g. [5, 20]\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m     train(description, \n\u001b[0;32m    222\u001b[0m           \u001b[39mself\u001b[39;49m, \n\u001b[0;32m    223\u001b[0m           TrainingSettings,\n\u001b[0;32m    224\u001b[0m           reinit, \n\u001b[0;32m    225\u001b[0m           callback, \n\u001b[0;32m    226\u001b[0m           callback_epochs,\n\u001b[0;32m    227\u001b[0m           xTest,\n\u001b[0;32m    228\u001b[0m           yTest)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\montecarlolearning\\train.py:62\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(description, Regressor, TrainingSettings, reinit, callback, callback_epochs, xTest, yTest)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39m# train one epoch\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m Regressor\u001b[39m.\u001b[39m_Generator\u001b[39m.\u001b[39mDifferential:\n\u001b[1;32m---> 62\u001b[0m     vanilla_train_one_epoch(\n\u001b[0;32m     63\u001b[0m         Regressor\u001b[39m.\u001b[39;49minputs, \n\u001b[0;32m     64\u001b[0m         Regressor\u001b[39m.\u001b[39;49mlabels, \n\u001b[0;32m     65\u001b[0m         Regressor\u001b[39m.\u001b[39;49mlearning_rate, \n\u001b[0;32m     66\u001b[0m         Regressor\u001b[39m.\u001b[39;49mminimizer, \n\u001b[0;32m     67\u001b[0m         Regressor\u001b[39m.\u001b[39;49mx, \n\u001b[0;32m     68\u001b[0m         Regressor\u001b[39m.\u001b[39;49my, \n\u001b[0;32m     69\u001b[0m         learning_rate, \n\u001b[0;32m     70\u001b[0m         batch_size, \n\u001b[0;32m     71\u001b[0m         Regressor\u001b[39m.\u001b[39;49msession)\n\u001b[0;32m     72\u001b[0m     i \u001b[39m=\u001b[39m i \u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     73\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m TrainingSettings\u001b[39m.\u001b[39mtestFrequency \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     74\u001b[0m         \u001b[39m#print('learning_rate for the last epoch was' + str(learning_rate))\u001b[39;00m\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\montecarlolearning\\vanilla_train_one_epoch.py:15\u001b[0m, in \u001b[0;36mvanilla_train_one_epoch\u001b[1;34m(inputs, labels, lr_placeholder, minimizer, x_train, y_train, learning_rate, batch_size, session)\u001b[0m\n\u001b[0;32m     13\u001b[0m last \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(batch_size, m) \u001b[39m#Assume batch size is 256, than first index = 0, after one loop first is at 256. If last is 750 (again index) we will ahve 3 iterations in while\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39mwhile\u001b[39;00m first \u001b[39m<\u001b[39m m:\n\u001b[1;32m---> 15\u001b[0m     session\u001b[39m.\u001b[39;49mrun(minimizer, feed_dict \u001b[39m=\u001b[39;49m {\n\u001b[0;32m     16\u001b[0m         inputs: x_train[first:last], \n\u001b[0;32m     17\u001b[0m         labels: y_train[first:last],\n\u001b[0;32m     18\u001b[0m         lr_placeholder: learning_rate\n\u001b[0;32m     19\u001b[0m     })\n\u001b[0;32m     20\u001b[0m     first \u001b[39m=\u001b[39m last\n\u001b[0;32m     21\u001b[0m     last \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(first \u001b[39m+\u001b[39m batch_size, m)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\client\\session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 968\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[0;32m    969\u001b[0m                      run_metadata_ptr)\n\u001b[0;32m    970\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[0;32m    971\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[39m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[39m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m \u001b[39mif\u001b[39;00m final_fetches \u001b[39mor\u001b[39;00m final_targets \u001b[39mor\u001b[39;00m (handle \u001b[39mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1191\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_run(handle, final_targets, final_fetches,\n\u001b[0;32m   1192\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m   results \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1368\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[0;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1371\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m   1372\u001b[0m                        run_metadata)\n\u001b[0;32m   1373\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_call\u001b[39m(\u001b[39mself\u001b[39m, fn, \u001b[39m*\u001b[39margs):\n\u001b[0;32m   1377\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m   1379\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1380\u001b[0m     message \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_text(e\u001b[39m.\u001b[39mmessage)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[0;32m   1359\u001b[0m   \u001b[39m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[0;32m   1360\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_graph()\n\u001b[1;32m-> 1361\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m   1362\u001b[0m                                   target_list, run_metadata)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_tf_sessionrun\u001b[39m(\u001b[39mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1453\u001b[0m                         run_metadata):\n\u001b[1;32m-> 1454\u001b[0m   \u001b[39mreturn\u001b[39;00m tf_session\u001b[39m.\u001b[39;49mTF_SessionRun_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session, options, feed_dict,\n\u001b[0;32m   1455\u001b[0m                                           fetch_list, target_list,\n\u001b[0;32m   1456\u001b[0m                                           run_metadata)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Copy of Main.py as a juypter notebook to visualize results\n",
    "\n",
    "###\n",
    "### 0. Import packages and references\n",
    "###\n",
    "### Import framework\n",
    "import os\n",
    "mainDirectory = os.path.abspath(os.path.join(os.getcwd(), '..','..', '..','..'))\n",
    "packageFile = os.path.abspath(os.path.join(mainDirectory, 'montecarlolearning', 'packages.py'))\n",
    "exec(open(packageFile).read())\n",
    "\n",
    "###\n",
    "### 1. Training data\n",
    "###\n",
    "#from CDF import *\n",
    "Generator = Multilevel_GBM(Multilevel_Train_Case.Euler, 5 ,Multilevel_Train_Dimension.one)\n",
    "Generator.set_inputName('S')\n",
    "Generator.set_outputName('EuropeanCallPrice(S)')\n",
    "\n",
    "###\n",
    "### 2. Set Nueral network structure / Hyperparameters\n",
    "### \n",
    "\n",
    "Regressor = Neural_Approximator()\n",
    "Regressor.set_Generator(Generator)\n",
    "Regressor.set_hiddenNeurons(20)\n",
    "Regressor.set_hiddenLayers(2)\n",
    "Regressor.set_activationFunctionsHidden(tf.nn.sigmoid)\n",
    "Regressor.set_activationFunctionOutput(tf.nn.sigmoid)\n",
    "Regressor.set_weight_seed(1)\n",
    "\n",
    "TrainSettings = TrainingSettings()\n",
    "TrainSettings.set_learning_rate_schedule( [(0.0, 0.01),  (0.2, 0.0001),  (0.4, 0.0001), (0.6, 0.0001),  (0.8, 0.0001)] )\n",
    "TrainSettings.set_min_batch_size(1)\n",
    "TrainSettings.set_test_frequency(100)\n",
    "TrainSettings.set_nTest(10000)\n",
    "TrainSettings.set_samplesPerStep(10000)\n",
    "TrainSettings.set_trainingSteps(5000)\n",
    "\n",
    "###\n",
    "### 3. Train network and Study results\n",
    "### Comment: For different trainingSetSizes the neural network reset and not saved, hence train and evaluation of yPredicted are done together currently\n",
    "###\n",
    "\n",
    "xTest, yTest, yPredicted = train_and_test(Generator, Regressor, TrainSettings)\n",
    "plot_results(\"predicted vs. expected\", yPredicted, xTest, yTest, Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\src\\Examples\\MultilevelMonteCarloLearning\\IntroductoryExample\\Implementation.ipynb Cell 2\u001b[0m in \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W1sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m TrainSettings\u001b[39m.\u001b[39mset_trainingSteps(\u001b[39m500\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W1sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W1sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m### 3. Train network and Study results\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W1sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m### Comment: For different trainingSetSizes the neural network reset and not saved, hence train and evaluation of yPredicted are done together currently\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W1sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W1sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m xTest, yTest, yPredicted \u001b[39m=\u001b[39m train_and_test(Generator, Regressor, TrainSettings)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W1sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m TrainSettings\u001b[39m.\u001b[39mset_samplesPerStep(\u001b[39m100000\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W1sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m xTest2, yTest2, yPredictedLevel1 \u001b[39m=\u001b[39m train_and_test(GeneratorLevel1, Regressor, TrainSettings)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\montecarlolearning\\train_and_test.py:89\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[1;34m(Generator, Regressor, TrainingSettings)\u001b[0m\n\u001b[0;32m     86\u001b[0m file_out\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39mtrain_steps, RMSE, Max_Error \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,TrainingSettings\u001b[39m.\u001b[39mTrainingSteps):\n\u001b[0;32m     88\u001b[0m     \u001b[39m#print('Training step ' + str(i) + ' will be done')\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m     xTrain, yTrain, _unused \u001b[39m=\u001b[39m Generator\u001b[39m.\u001b[39;49mtrainingSet(TrainingSettings\u001b[39m.\u001b[39;49mSamplesPerStep, trainSeed\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m     91\u001b[0m     \u001b[39m# ToDo: rethink this. It doesn't work without this, see e.g. closed path gbm. \u001b[39;00m\n\u001b[0;32m     92\u001b[0m     \u001b[39m# Since data is generated each time, the first normalization is not correct later...\u001b[39;00m\n\u001b[0;32m     93\u001b[0m     \u001b[39m# Idea: Perhaps with max/min of intervals, to overcome border cases...?\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     Regressor\u001b[39m.\u001b[39mstoreNewDataAndNormalize(xTrain,  yTrain, _unused, TrainingSettings\u001b[39m.\u001b[39mSamplesPerStep)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\montecarlolearning\\Multilevel_GBM.py:122\u001b[0m, in \u001b[0;36mMultilevel_GBM.trainingSet\u001b[1;34m(self, m, trainSeed, approx)\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[39m# 3. Calculate and return payoffs\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     payoffs \u001b[39m=\u001b[39m discountedPayoff(s,mu,T,K)\n\u001b[1;32m--> 122\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mstack((s_0,sigma,mu,T,K),axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), payoffs\u001b[39m.\u001b[39mreshape([\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m]), \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39melif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_opt \u001b[39m==\u001b[39m Multilevel_Train_Case\u001b[39m.\u001b[39mGBM_Path_Solution):\n\u001b[0;32m    124\u001b[0m     \u001b[39m#3. sets of random returns\u001b[39;00m\n\u001b[0;32m    125\u001b[0m     h\u001b[39m=\u001b[39mT[:]\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\numpy\\core\\shape_base.py:433\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out)\u001b[0m\n\u001b[0;32m    431\u001b[0m sl \u001b[39m=\u001b[39m (\u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m),) \u001b[39m*\u001b[39m axis \u001b[39m+\u001b[39m (_nx\u001b[39m.\u001b[39mnewaxis,)\n\u001b[0;32m    432\u001b[0m expanded_arrays \u001b[39m=\u001b[39m [arr[sl] \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 433\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(expanded_arrays, axis\u001b[39m=\u001b[39;49maxis, out\u001b[39m=\u001b[39;49mout)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###\n",
    "### 1. Training data\n",
    "###\n",
    "#from CDF import *\n",
    "Generator = Multilevel_GBM(Multilevel_Train_Case.Milstein, 0, Multilevel_Train_Dimension.one)\n",
    "Generator.set_inputName('S')\n",
    "Generator.set_outputName('P_0')\n",
    "\n",
    "GeneratorLevel1 = Multilevel_GBM(Multilevel_Train_Case.LevelEstimator, 0, Multilevel_Train_Dimension.one)\n",
    "GeneratorLevel1 .set_inputName('x')\n",
    "GeneratorLevel1 .set_outputName('P_1-P_0')\n",
    "\n",
    "GeneratorLevel2 = Multilevel_GBM(Multilevel_Train_Case.LevelEstimator, 1, Multilevel_Train_Dimension.one)\n",
    "GeneratorLevel2 .set_inputName('x')\n",
    "GeneratorLevel2 .set_outputName('P_2-P_1')\n",
    "\n",
    "GeneratorLevel3 = Multilevel_GBM(Multilevel_Train_Case.LevelEstimator, 2, Multilevel_Train_Dimension.one)\n",
    "GeneratorLevel3 .set_inputName('x')\n",
    "GeneratorLevel3 .set_outputName('P_3-P_2')\n",
    "\n",
    "GeneratorLevel4 = Multilevel_GBM(Multilevel_Train_Case.LevelEstimator, 3, Multilevel_Train_Dimension.one)\n",
    "GeneratorLevel4 .set_inputName('x')\n",
    "GeneratorLevel4 .set_outputName('P_4-P_3')\n",
    "\n",
    "\n",
    "###\n",
    "### 2. Set Nueral network structure / Hyperparameters\n",
    "### \n",
    "\n",
    "Regressor = Neural_Approximator()\n",
    "Regressor.set_Generator(Generator)\n",
    "Regressor.set_hiddenNeurons(20)\n",
    "Regressor.set_hiddenLayers(2)\n",
    "Regressor.set_activationFunctionsHidden(tf.nn.sigmoid)\n",
    "Regressor.set_activationFunctionOutput(tf.nn.sigmoid)\n",
    "Regressor.set_weight_seed(1)\n",
    "\n",
    "TrainSettings = TrainingSettings()\n",
    "TrainSettings.set_learning_rate_schedule=([(0.0, 0.0001),  (0.2, 0.0001),  (0.4, 0.0001), (0.6, 0.0001),  (0.8, 0.0001)] )\n",
    "TrainSettings.set_min_batch_size(1)\n",
    "TrainSettings.set_test_frequency(100)\n",
    "TrainSettings.set_nTest(100000)\n",
    "TrainSettings.set_samplesPerStep(400000)\n",
    "TrainSettings.set_trainingSteps(500)\n",
    "\n",
    "###\n",
    "### 3. Train network and Study results\n",
    "### Comment: For different trainingSetSizes the neural network reset and not saved, hence train and evaluation of yPredicted are done together currently\n",
    "###\n",
    "\n",
    "xTest, yTest, yPredicted = train_and_test(Generator, Regressor, TrainSettings)\n",
    "TrainSettings.set_samplesPerStep(100000)\n",
    "xTest2, yTest2, yPredictedLevel1 = train_and_test(GeneratorLevel1, Regressor, TrainSettings)\n",
    "TrainSettings.set_samplesPerStep(25000)\n",
    "xTest, yTest, yPredictedLevel2 = train_and_test(GeneratorLevel2, Regressor, TrainSettings)\n",
    "TrainSettings.set_samplesPerStep(10000)\n",
    "xTest, yTest, yPredictedLevel3 = train_and_test(GeneratorLevel3, Regressor, TrainSettings)\n",
    "xTest, yTest, yPredictedLevel4 = train_and_test(GeneratorLevel4, Regressor, TrainSettings)\n",
    "multilevel_predicted = {('standard', 100000): np.add(yPredicted[('standard', 100000)], yPredictedLevel1[('standard', 100000)])}\n",
    "multilevel_predicted = {('standard', 100000): np.add(multilevel_predicted[('standard', 100000)], yPredictedLevel2[('standard', 100000)])}\n",
    "multilevel_predicted = {('standard', 100000): np.add(multilevel_predicted[('standard', 100000)], yPredictedLevel3[('standard', 100000)])}\n",
    "multilevel_predicted = {('standard', 100000): np.add(multilevel_predicted[('standard', 100000)], yPredictedLevel4[('standard', 100000)])}\n",
    "plot_results(\"predicted vs. expected\", multilevel_predicted, xTest, yTest, Generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83a8566224840326395a21c083192bd4c5adbde2ed4f12bcb51b671fb460c3a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
