{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU support =  False\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'while_loop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\src\\Examples\\MultilevelMonteCarloLearning\\IntroductoryExample\\Implementation.ipynb Cell 1\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m TrainSettings\u001b[39m.\u001b[39mset_trainingSteps(\u001b[39m1000\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m### 3. Train network and Study results\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m### Comment: For different trainingSetSizes the neural network reset and not saved, hence train and evaluation of yPredicted are done together currently\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m xTest, yTest, yPredicted \u001b[39m=\u001b[39m train_and_test(Generator, Regressor, TrainSettings)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m plot_results(\u001b[39m\"\u001b[39m\u001b[39mpredicted vs. expected\u001b[39m\u001b[39m\"\u001b[39m, yPredicted, xTest, yTest, Generator)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\montecarlolearning\\train_and_test.py:68\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[1;34m(Generator, Regressor, TrainingSettings)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39melif\u001b[39;00m Generator\u001b[39m.\u001b[39mTrainMethod \u001b[39m==\u001b[39m TrainingMethod\u001b[39m.\u001b[39mGenerateDataDuringTraining:\n\u001b[0;32m     63\u001b[0m     \u001b[39m# Parameters for GenerateDataDuringTraining\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m     \u001b[39m# 1. Simulation of initial training set\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39m#print(\"Simulating initial training set and test set\")\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     initial_sample_amount \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(TrainingSettings\u001b[39m.\u001b[39mSamplesPerStep,\u001b[39m10000\u001b[39m) \u001b[39m# to get a proper batch normalization\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     xTrain, yTrain, _unused \u001b[39m=\u001b[39m Generator\u001b[39m.\u001b[39;49mtrainingSet(initial_sample_amount, trainSeed\u001b[39m=\u001b[39;49mGenerator\u001b[39m.\u001b[39;49mdataSeed)\n\u001b[0;32m     69\u001b[0m     xTest, yTest, _unused, _unused2 \u001b[39m=\u001b[39m Generator\u001b[39m.\u001b[39mtestSet(num\u001b[39m=\u001b[39mTrainingSettings\u001b[39m.\u001b[39mnTest, testSeed\u001b[39m=\u001b[39mGenerator\u001b[39m.\u001b[39mtestSeed)\n\u001b[0;32m     70\u001b[0m     \u001b[39m#print(\"done\")\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \n\u001b[0;32m     72\u001b[0m     \u001b[39m# 2. Neural network initialization \u001b[39;00m\n\u001b[0;32m     73\u001b[0m     \u001b[39m#print(\"initializing neural appropximator\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\montecarlolearning\\Multilevel_GBM.py:61\u001b[0m, in \u001b[0;36mMultilevel_GBM.trainingSet\u001b[1;34m(self, m, trainSeed, approx)\u001b[0m\n\u001b[0;32m     59\u001b[0m s \u001b[39m=\u001b[39m s_0\n\u001b[0;32m     60\u001b[0m \u001b[39m# Run the while loop using NumPy\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m s \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mwhile_loop(np_cond, np_func, [i, s])\n\u001b[0;32m     62\u001b[0m \u001b[39m# 2. Compute paths\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39m#h = T[:]/ self._steps\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39m#z=np.random.normal(0.0, 1.0, m)\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[39m#s= s_0[:] + mu[:] *s_0[:] * h[:] +sigma[:] * s_0[:] *np.sqrt(h[:])*z[:] + 0.5 *sigma[:] *s_0[:] *sigma[:] * ((np.sqrt(h[:])*z[:])**2-h[:]) \u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[39m# 3. Calculate and return payoffs\u001b[39;00m\n\u001b[0;32m     67\u001b[0m payoffs\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39mmu[:] \u001b[39m*\u001b[39m T[:])\u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mmaximum(s[:] \u001b[39m-\u001b[39m K[:], \u001b[39m0.\u001b[39m)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\numpy\\__init__.py:311\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mimport\u001b[39;00m Tester\n\u001b[0;32m    309\u001b[0m     \u001b[39mreturn\u001b[39;00m Tester\n\u001b[1;32m--> 311\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    312\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'while_loop'"
     ]
    }
   ],
   "source": [
    "### Copy of Main.py as a juypter notebook to visualize results\n",
    "\n",
    "###\n",
    "### 0. Import packages and references\n",
    "###\n",
    "### Import framework\n",
    "import os\n",
    "mainDirectory = os.path.abspath(os.path.join(os.getcwd(), '..','..', '..','..'))\n",
    "packageFile = os.path.abspath(os.path.join(mainDirectory, 'montecarlolearning', 'packages.py'))\n",
    "exec(open(packageFile).read())\n",
    "\n",
    "###\n",
    "### 1. Training data\n",
    "###\n",
    "#from CDF import *\n",
    "Generator = Multilevel_GBM(Multilevel_Train_Case.Milstein)\n",
    "Generator.set_inputName('S')\n",
    "Generator.set_outputName('EuropeanCallPrice(S)')\n",
    "\n",
    "###\n",
    "### 2. Set Nueral network structure / Hyperparameters\n",
    "### \n",
    "\n",
    "Regressor = Neural_Approximator()\n",
    "Regressor.set_Generator(Generator)\n",
    "Regressor.set_hiddenNeurons(50)\n",
    "Regressor.set_hiddenLayers(2)\n",
    "Regressor.set_activationFunctionsHidden(tf.nn.sigmoid)\n",
    "Regressor.set_activationFunctionOutput(tf.nn.sigmoid)\n",
    "Regressor.set_weight_seed(1)\n",
    "\n",
    "TrainSettings = TrainingSettings()\n",
    "TrainSettings.set_learning_rate_schedule=([(0.0, 0.0001),  (0.2, 0.0001),  (0.4, 0.0001), (0.6, 0.0001),  (0.8, 0.0001)] )\n",
    "TrainSettings.set_min_batch_size(1)\n",
    "TrainSettings.set_test_frequency(100)\n",
    "TrainSettings.set_nTest(100000)\n",
    "TrainSettings.set_samplesPerStep(200000)\n",
    "TrainSettings.set_trainingSteps(1000)\n",
    "\n",
    "###\n",
    "### 3. Train network and Study results\n",
    "### Comment: For different trainingSetSizes the neural network reset and not saved, hence train and evaluation of yPredicted are done together currently\n",
    "###\n",
    "\n",
    "xTest, yTest, yPredicted = train_and_test(Generator, Regressor, TrainSettings)\n",
    "plot_results(\"predicted vs. expected\", yPredicted, xTest, yTest, Generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83a8566224840326395a21c083192bd4c5adbde2ed4f12bcb51b671fb460c3a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
