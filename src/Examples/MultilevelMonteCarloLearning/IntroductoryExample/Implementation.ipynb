{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU support =  False\n",
      "RMSE after 100 training steps is [0.15286069]\n",
      "RMSE after 200 training steps is [0.51473154]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DanielPrivateGitHub\\Documents\\GitHub\\NeuronalNetworkTensorflowFramework\\src\\Examples\\MultilevelMonteCarloLearning\\IntroductoryExample\\Implementation.ipynb Cell 1\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DanielPrivateGitHub/Documents/GitHub/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m TrainSettings\u001b[39m.\u001b[39mset_trainingSteps(\u001b[39m1000\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DanielPrivateGitHub/Documents/GitHub/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DanielPrivateGitHub/Documents/GitHub/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m### 3. Train network and Study results\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DanielPrivateGitHub/Documents/GitHub/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m### Comment: For different trainingSetSizes the neural network reset and not saved, hence train and evaluation of yPredicted are done together currently\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DanielPrivateGitHub/Documents/GitHub/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DanielPrivateGitHub/Documents/GitHub/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m xTest, yTest, yPredicted \u001b[39m=\u001b[39m train_and_test(Generator, Regressor, TrainSettings)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DanielPrivateGitHub/Documents/GitHub/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m plot_results(\u001b[39m\"\u001b[39m\u001b[39mpredicted vs. expected\u001b[39m\u001b[39m\"\u001b[39m, yPredicted, xTest, yTest, Generator)\n",
      "File \u001b[1;32mc:\\Users\\DanielPrivateGitHub\\Documents\\GitHub\\NeuronalNetworkTensorflowFramework\\montecarlolearning\\train_and_test.py:92\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[1;34m(Generator, Regressor, TrainingSettings)\u001b[0m\n\u001b[0;32m     87\u001b[0m xTrain, yTrain, _unused \u001b[39m=\u001b[39m Generator\u001b[39m.\u001b[39mtrainingSet(TrainingSettings\u001b[39m.\u001b[39mSamplesPerStep, trainSeed\u001b[39m=\u001b[39mi)\n\u001b[0;32m     89\u001b[0m \u001b[39m# ToDo: rethink this. It doesn't work without this, see e.g. closed path gbm. \u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[39m# Since data is generated each time, the first normalization is not correct later...\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39m# Idea: Perhaps with max/min of intervals, to overcome border cases...?\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m Regressor\u001b[39m.\u001b[39;49mstoreNewDataAndNormalize(xTrain,  yTrain, _unused, TrainingSettings\u001b[39m.\u001b[39;49mSamplesPerStep)\n\u001b[0;32m     94\u001b[0m \u001b[39m# 4. Train network\u001b[39;00m\n\u001b[0;32m     95\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\DanielPrivateGitHub\\Documents\\GitHub\\NeuronalNetworkTensorflowFramework\\montecarlolearning\\Neural_Approximator.py:139\u001b[0m, in \u001b[0;36mNeural_Approximator.storeNewDataAndNormalize\u001b[1;34m(self, x_raw, y_raw, dydx_raw, dataSize)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_raw \u001b[39m=\u001b[39m y_raw\n\u001b[0;32m    137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdydx_raw \u001b[39m=\u001b[39m dydx_raw\n\u001b[0;32m    138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_mean, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_std, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_mean, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_std, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdy_dx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlambda_j \u001b[39m=\u001b[39m \\\n\u001b[1;32m--> 139\u001b[0m     normalize_data(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx_raw, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_raw, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdydx_raw, dataSize)\n",
      "File \u001b[1;32mc:\\Users\\DanielPrivateGitHub\\Documents\\GitHub\\NeuronalNetworkTensorflowFramework\\montecarlolearning\\normalize_data.py:15\u001b[0m, in \u001b[0;36mnormalize_data\u001b[1;34m(x_raw, y_raw, dydx_raw, crop)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# normalize dataset\u001b[39;00m\n\u001b[0;32m     14\u001b[0m x_mean \u001b[39m=\u001b[39m x_cropped\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m x_std \u001b[39m=\u001b[39m x_cropped\u001b[39m.\u001b[39;49mstd(axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m) \u001b[39m+\u001b[39m epsilon\n\u001b[0;32m     16\u001b[0m x \u001b[39m=\u001b[39m (x_cropped\u001b[39m-\u001b[39m x_mean) \u001b[39m/\u001b[39m x_std\n\u001b[0;32m     17\u001b[0m y_mean \u001b[39m=\u001b[39m y_cropped\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\DanielPrivateGitHub\\Documents\\GitHub\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\numpy\\core\\_methods.py:265\u001b[0m, in \u001b[0;36m_std\u001b[1;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_std\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, ddof\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m,\n\u001b[0;32m    264\u001b[0m          where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 265\u001b[0m     ret \u001b[39m=\u001b[39m _var(a, axis\u001b[39m=\u001b[39;49maxis, dtype\u001b[39m=\u001b[39;49mdtype, out\u001b[39m=\u001b[39;49mout, ddof\u001b[39m=\u001b[39;49mddof,\n\u001b[0;32m    266\u001b[0m                keepdims\u001b[39m=\u001b[39;49mkeepdims, where\u001b[39m=\u001b[39;49mwhere)\n\u001b[0;32m    268\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ret, mu\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m    269\u001b[0m         ret \u001b[39m=\u001b[39m um\u001b[39m.\u001b[39msqrt(ret, out\u001b[39m=\u001b[39mret)\n",
      "File \u001b[1;32mc:\\Users\\DanielPrivateGitHub\\Documents\\GitHub\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\numpy\\core\\_methods.py:233\u001b[0m, in \u001b[0;36m_var\u001b[1;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[0;32m    228\u001b[0m     arrmean \u001b[39m=\u001b[39m arrmean \u001b[39m/\u001b[39m rcount\n\u001b[0;32m    230\u001b[0m \u001b[39m# Compute sum of squared deviations from mean\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[39m# Note that x may not be inexact and that we need it to be an array,\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[39m# not a scalar.\u001b[39;00m\n\u001b[1;32m--> 233\u001b[0m x \u001b[39m=\u001b[39m asanyarray(arr \u001b[39m-\u001b[39;49m arrmean)\n\u001b[0;32m    235\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(arr\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, (nt\u001b[39m.\u001b[39mfloating, nt\u001b[39m.\u001b[39minteger)):\n\u001b[0;32m    236\u001b[0m     x \u001b[39m=\u001b[39m um\u001b[39m.\u001b[39mmultiply(x, x, out\u001b[39m=\u001b[39mx)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Copy of Main.py as a juypter notebook to visualize results\n",
    "\n",
    "###\n",
    "### 0. Import packages and references\n",
    "###\n",
    "### Import framework\n",
    "import os\n",
    "mainDirectory = os.path.abspath(os.path.join(os.getcwd(), '..','..', '..','..'))\n",
    "packageFile = os.path.abspath(os.path.join(mainDirectory, 'montecarlolearning', 'packages.py'))\n",
    "exec(open(packageFile).read())\n",
    "\n",
    "###\n",
    "### 1. Training data\n",
    "###\n",
    "#from CDF import *\n",
    "Generator = Multilevel_GBM(Multilevel_Train_Case.GBM_Path_Solution, 1 ,Multilevel_Train_Dimension.one)\n",
    "Generator.set_inputName('S')\n",
    "Generator.set_outputName('EuropeanCallPrice(S)')\n",
    "\n",
    "###\n",
    "### 2. Set Nueral network structure / Hyperparameters\n",
    "### \n",
    "\n",
    "Regressor = Neural_Approximator()\n",
    "Regressor.set_Generator(Generator)\n",
    "Regressor.set_hiddenNeurons(20)\n",
    "Regressor.set_hiddenLayers(2)\n",
    "Regressor.set_activationFunctionsHidden(tf.nn.sigmoid)\n",
    "Regressor.set_activationFunctionOutput(tf.nn.sigmoid)\n",
    "Regressor.set_weight_seed(1)\n",
    "\n",
    "TrainSettings = TrainingSettings()\n",
    "TrainSettings.set_learning_rate_schedule=([(0.0, 0.0001),  (0.2, 0.0001),  (0.4, 0.0001), (0.6, 0.0001),  (0.8, 0.0001)] )\n",
    "TrainSettings.set_min_batch_size(1)\n",
    "TrainSettings.set_test_frequency(100)\n",
    "TrainSettings.set_nTest(100000)\n",
    "TrainSettings.set_samplesPerStep(200000)\n",
    "TrainSettings.set_trainingSteps(1000)\n",
    "\n",
    "###\n",
    "### 3. Train network and Study results\n",
    "### Comment: For different trainingSetSizes the neural network reset and not saved, hence train and evaluation of yPredicted are done together currently\n",
    "###\n",
    "\n",
    "xTest, yTest, yPredicted = train_and_test(Generator, Regressor, TrainSettings)\n",
    "plot_results(\"predicted vs. expected\", yPredicted, xTest, yTest, Generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83a8566224840326395a21c083192bd4c5adbde2ed4f12bcb51b671fb460c3a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
