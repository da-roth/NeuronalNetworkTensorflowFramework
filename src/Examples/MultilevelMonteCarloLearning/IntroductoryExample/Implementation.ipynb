{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU support =  False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\src\\Examples\\MultilevelMonteCarloLearning\\IntroductoryExample\\Implementation.ipynb Cell 1\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m TrainSettings\u001b[39m.\u001b[39mset_trainingSteps(\u001b[39m5000\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m### 3. Train network and Study results\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m### Comment: For different trainingSetSizes the neural network reset and not saved, hence train and evaluation of yPredicted are done together currently\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m xTest, yTest, yPredicted \u001b[39m=\u001b[39m train_and_test(Generator, Regressor, TrainSettings)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W0sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m plot_results(\u001b[39m\"\u001b[39m\u001b[39mpredicted vs. expected\u001b[39m\u001b[39m\"\u001b[39m, yPredicted, xTest, yTest, Generator)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\montecarlolearning\\train_and_test.py:90\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[1;34m(Generator, Regressor, TrainSettings)\u001b[0m\n\u001b[0;32m     87\u001b[0m file_out\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39mtrain_steps, RMSE, Max_Error \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,TrainSettings\u001b[39m.\u001b[39mTrainingSteps):\n\u001b[0;32m     89\u001b[0m     \u001b[39m#print('Training step ' + str(i) + ' will be done')\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m     xTrain, yTrain, _unused \u001b[39m=\u001b[39m Generator\u001b[39m.\u001b[39;49mtrainingSet(TrainSettings\u001b[39m.\u001b[39;49mSamplesPerStep, trainSeed\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m     92\u001b[0m     \u001b[39m# ToDo: rethink this. It doesn't work without this, see e.g. closed path gbm. \u001b[39;00m\n\u001b[0;32m     93\u001b[0m     \u001b[39m# Since data is generated each time, the first normalization is not correct later...\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     \u001b[39m# Idea: Perhaps with max/min of intervals, to overcome border cases...?\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     Regressor\u001b[39m.\u001b[39mstoreNewDataAndNormalize(xTrain,  yTrain, _unused, TrainSettings\u001b[39m.\u001b[39mSamplesPerStep)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\montecarlolearning\\Multilevel_GBM.py:93\u001b[0m, in \u001b[0;36mMultilevel_GBM.trainingSet\u001b[1;34m(self, m, trainSeed, approx)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39m# # 1. Draw parameter samples for training\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[39m# s_0 = (self.s_0_trainInterval[1] - self.s_0_trainInterval[0]) * np.random.random_sample(m) + self.s_0_trainInterval[0]\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[39m# sigma = (self.sigma_trainInterval[1] - self.sigma_trainInterval[0]) * np.random.random_sample(m) + self.sigma_trainInterval[0]\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[39m# mu = (self.mu_trainInterval[1] - self.mu_trainInterval[0]) * np.random.random_sample(m) + self.mu_trainInterval[0]\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[39m# T = (self.T_trainInterval[1] - self.T_trainInterval[0]) * np.random.random_sample(m) + self.T_trainInterval[0]\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39m# K = (self.K_trainInterval[1] - self.K_trainInterval[0]) * np.random.random_sample(m) + self.K_trainInterval[0]\u001b[39;00m\n\u001b[0;32m     92\u001b[0m s_0 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(shape\u001b[39m=\u001b[39m(m,), minval\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39ms_0_trainInterval[\u001b[39m0\u001b[39m], maxval\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39ms_0_trainInterval[\u001b[39m1\u001b[39m], dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m---> 93\u001b[0m sigma \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49muniform(shape\u001b[39m=\u001b[39;49m(m,), minval\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msigma_trainInterval[\u001b[39m0\u001b[39;49m], maxval\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msigma_trainInterval[\u001b[39m1\u001b[39;49m], dtype\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mfloat32)\n\u001b[0;32m     94\u001b[0m mu \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(shape\u001b[39m=\u001b[39m(m,), minval\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmu_trainInterval[\u001b[39m0\u001b[39m], maxval\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmu_trainInterval[\u001b[39m1\u001b[39m], dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m     95\u001b[0m T \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(shape\u001b[39m=\u001b[39m(m,), minval\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mT_trainInterval[\u001b[39m0\u001b[39m], maxval\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mT_trainInterval[\u001b[39m1\u001b[39m], dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py:309\u001b[0m, in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[0;32m    306\u001b[0m   result \u001b[39m=\u001b[39m gen_random_ops\u001b[39m.\u001b[39mrandom_uniform_int(\n\u001b[0;32m    307\u001b[0m       shape, minval, maxval, seed\u001b[39m=\u001b[39mseed1, seed2\u001b[39m=\u001b[39mseed2, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m    308\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 309\u001b[0m   result \u001b[39m=\u001b[39m gen_random_ops\u001b[39m.\u001b[39;49mrandom_uniform(\n\u001b[0;32m    310\u001b[0m       shape, dtype, seed\u001b[39m=\u001b[39;49mseed1, seed2\u001b[39m=\u001b[39;49mseed2)\n\u001b[0;32m    311\u001b[0m   \u001b[39mif\u001b[39;00m minval_is_zero:\n\u001b[0;32m    312\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m maxval_is_one:\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py:736\u001b[0m, in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[0;32m    734\u001b[0m   seed2 \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    735\u001b[0m seed2 \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_int(seed2, \u001b[39m\"\u001b[39m\u001b[39mseed2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 736\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m    737\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mRandomUniform\u001b[39;49m\u001b[39m\"\u001b[39;49m, shape\u001b[39m=\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49mdtype, seed\u001b[39m=\u001b[39;49mseed, seed2\u001b[39m=\u001b[39;49mseed2,\n\u001b[0;32m    738\u001b[0m                        name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m    739\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m    740\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    793\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    794\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    795\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    796\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    798\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    799\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    801\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3800\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3797\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3800\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[0;32m   3801\u001b[0m       node_def,\n\u001b[0;32m   3802\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3803\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3804\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3805\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3806\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3807\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3808\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   3809\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3810\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2109\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2107\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[0;32m   2108\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39mop_def)\n\u001b[1;32m-> 2109\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_from_c_op(c_op\u001b[39m=\u001b[39;49mc_op, g\u001b[39m=\u001b[39;49mg)\n\u001b[0;32m   2111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_op \u001b[39m=\u001b[39m original_op\n\u001b[0;32m   2113\u001b[0m \u001b[39m# Post process for control flows.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2187\u001b[0m, in \u001b[0;36mOperation._init_from_c_op\u001b[1;34m(self, c_op, g)\u001b[0m\n\u001b[0;32m   2184\u001b[0m   tensor \u001b[39m=\u001b[39m Tensor\u001b[39m.\u001b[39m_create_with_tf_output(\u001b[39mself\u001b[39m, i, output_type, tf_output)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2185\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs\u001b[39m.\u001b[39mappend(tensor)\n\u001b[1;32m-> 2187\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id_value \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39m_add_op(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2249\u001b[0m, in \u001b[0;36mOperation.name\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2246\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m   2247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mname\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   2248\u001b[0m   \u001b[39m\"\"\"The full name of this operation.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2249\u001b[0m   \u001b[39mreturn\u001b[39;00m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_OperationName(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_c_op)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Copy of Main.py as a juypter notebook to visualize results\n",
    "\n",
    "###\n",
    "### 0. Import packages and references\n",
    "###\n",
    "### Import framework\n",
    "import os\n",
    "mainDirectory = os.path.abspath(os.path.join(os.getcwd(), '..','..', '..','..'))\n",
    "packageFile = os.path.abspath(os.path.join(mainDirectory, 'montecarlolearning', 'packages.py'))\n",
    "exec(open(packageFile).read())\n",
    "\n",
    "###\n",
    "### 1. Training data\n",
    "###\n",
    "#from CDF import *\n",
    "Generator = Multilevel_GBM(Multilevel_Train_Case.Euler, 0 ,Multilevel_Train_Dimension.one)\n",
    "Generator.set_inputName('S')\n",
    "Generator.set_outputName('EuropeanCallPrice(S)')\n",
    "\n",
    "###\n",
    "### 2. Set Nueral network structure / \n",
    "# Hyperparameters\n",
    "### \n",
    "\n",
    "Regressor = Neural_Approximator()\n",
    "Regressor.set_Generator(Generator)\n",
    "Regressor.set_hiddenNeurons(20)\n",
    "Regressor.set_hiddenLayers(2)\n",
    "Regressor.set_activationFunctionsHidden(tf.nn.sigmoid)\n",
    "Regressor.set_activationFunctionOutput(tf.nn.sigmoid)\n",
    "Regressor.set_weight_seed(1)\n",
    "\n",
    "TrainSettings = TrainingSettings()\n",
    "TrainSettings.useExponentialDecay(0.01, 0.1, 1000)\n",
    "TrainSettings.set_min_batch_size(1)\n",
    "TrainSettings.set_test_frequency(10)\n",
    "TrainSettings.set_nTest(10000)\n",
    "TrainSettings.set_samplesPerStep(10000)\n",
    "TrainSettings.set_trainingSteps(5000)\n",
    "\n",
    "###\n",
    "### 3. Train network and Study results\n",
    "### Comment: For different trainingSetSizes the neural network reset and not saved, hence train and evaluation of yPredicted are done together currently\n",
    "###\n",
    "\n",
    "xTest, yTest, yPredicted = train_and_test(Generator, Regressor, TrainSettings)\n",
    "plot_results(\"predicted vs. expected\", yPredicted, xTest, yTest, Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\src\\Examples\\MultilevelMonteCarloLearning\\IntroductoryExample\\Implementation.ipynb Cell 2\u001b[0m in \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W1sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m TrainSettings\u001b[39m.\u001b[39mset_trainingSteps(\u001b[39m500\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W1sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W1sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m### 3. Train network and Study results\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W1sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m### Comment: For different trainingSetSizes the neural network reset and not saved, hence train and evaluation of yPredicted are done together currently\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W1sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W1sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m xTest, yTest, yPredicted \u001b[39m=\u001b[39m train_and_test(Generator, Regressor, TrainSettings)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W1sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m TrainSettings\u001b[39m.\u001b[39mset_samplesPerStep(\u001b[39m100000\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/NeuronalNetworkTensorflowFramework/src/Examples/MultilevelMonteCarloLearning/IntroductoryExample/Implementation.ipynb#W1sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m xTest2, yTest2, yPredictedLevel1 \u001b[39m=\u001b[39m train_and_test(GeneratorLevel1, Regressor, TrainSettings)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\montecarlolearning\\train_and_test.py:89\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[1;34m(Generator, Regressor, TrainingSettings)\u001b[0m\n\u001b[0;32m     86\u001b[0m file_out\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39mtrain_steps, RMSE, Max_Error \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,TrainingSettings\u001b[39m.\u001b[39mTrainingSteps):\n\u001b[0;32m     88\u001b[0m     \u001b[39m#print('Training step ' + str(i) + ' will be done')\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m     xTrain, yTrain, _unused \u001b[39m=\u001b[39m Generator\u001b[39m.\u001b[39;49mtrainingSet(TrainingSettings\u001b[39m.\u001b[39;49mSamplesPerStep, trainSeed\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m     91\u001b[0m     \u001b[39m# ToDo: rethink this. It doesn't work without this, see e.g. closed path gbm. \u001b[39;00m\n\u001b[0;32m     92\u001b[0m     \u001b[39m# Since data is generated each time, the first normalization is not correct later...\u001b[39;00m\n\u001b[0;32m     93\u001b[0m     \u001b[39m# Idea: Perhaps with max/min of intervals, to overcome border cases...?\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     Regressor\u001b[39m.\u001b[39mstoreNewDataAndNormalize(xTrain,  yTrain, _unused, TrainingSettings\u001b[39m.\u001b[39mSamplesPerStep)\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\montecarlolearning\\Multilevel_GBM.py:122\u001b[0m, in \u001b[0;36mMultilevel_GBM.trainingSet\u001b[1;34m(self, m, trainSeed, approx)\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[39m# 3. Calculate and return payoffs\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     payoffs \u001b[39m=\u001b[39m discountedPayoff(s,mu,T,K)\n\u001b[1;32m--> 122\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mstack((s_0,sigma,mu,T,K),axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), payoffs\u001b[39m.\u001b[39mreshape([\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m]), \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39melif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_opt \u001b[39m==\u001b[39m Multilevel_Train_Case\u001b[39m.\u001b[39mGBM_Path_Solution):\n\u001b[0;32m    124\u001b[0m     \u001b[39m#3. sets of random returns\u001b[39;00m\n\u001b[0;32m    125\u001b[0m     h\u001b[39m=\u001b[39mT[:]\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\dev\\NeuronalNetworkTensorflowFramework\\.venvNN\\lib\\site-packages\\numpy\\core\\shape_base.py:433\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out)\u001b[0m\n\u001b[0;32m    431\u001b[0m sl \u001b[39m=\u001b[39m (\u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m),) \u001b[39m*\u001b[39m axis \u001b[39m+\u001b[39m (_nx\u001b[39m.\u001b[39mnewaxis,)\n\u001b[0;32m    432\u001b[0m expanded_arrays \u001b[39m=\u001b[39m [arr[sl] \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 433\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(expanded_arrays, axis\u001b[39m=\u001b[39;49maxis, out\u001b[39m=\u001b[39;49mout)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###\n",
    "### 1. Training data\n",
    "###\n",
    "#from CDF import *\n",
    "Generator = Multilevel_GBM(Multilevel_Train_Case.Milstein, 0, Multilevel_Train_Dimension.one)\n",
    "Generator.set_inputName('S')\n",
    "Generator.set_outputName('P_0')\n",
    "\n",
    "GeneratorLevel1 = Multilevel_GBM(Multilevel_Train_Case.LevelEstimator, 0, Multilevel_Train_Dimension.one)\n",
    "GeneratorLevel1 .set_inputName('x')\n",
    "GeneratorLevel1 .set_outputName('P_1-P_0')\n",
    "\n",
    "GeneratorLevel2 = Multilevel_GBM(Multilevel_Train_Case.LevelEstimator, 1, Multilevel_Train_Dimension.one)\n",
    "GeneratorLevel2 .set_inputName('x')\n",
    "GeneratorLevel2 .set_outputName('P_2-P_1')\n",
    "\n",
    "GeneratorLevel3 = Multilevel_GBM(Multilevel_Train_Case.LevelEstimator, 2, Multilevel_Train_Dimension.one)\n",
    "GeneratorLevel3 .set_inputName('x')\n",
    "GeneratorLevel3 .set_outputName('P_3-P_2')\n",
    "\n",
    "GeneratorLevel4 = Multilevel_GBM(Multilevel_Train_Case.LevelEstimator, 3, Multilevel_Train_Dimension.one)\n",
    "GeneratorLevel4 .set_inputName('x')\n",
    "GeneratorLevel4 .set_outputName('P_4-P_3')\n",
    "\n",
    "\n",
    "###\n",
    "### 2. Set Nueral network structure / Hyperparameters\n",
    "### \n",
    "\n",
    "Regressor = Neural_Approximator()\n",
    "Regressor.set_Generator(Generator)\n",
    "Regressor.set_hiddenNeurons(20)\n",
    "Regressor.set_hiddenLayers(2)\n",
    "Regressor.set_activationFunctionsHidden(tf.nn.sigmoid)\n",
    "Regressor.set_activationFunctionOutput(tf.nn.sigmoid)\n",
    "Regressor.set_weight_seed(1)\n",
    "\n",
    "TrainSettings = TrainingSettings()\n",
    "TrainSettings.set_learning_rate_schedule=([(0.0, 0.0001),  (0.2, 0.0001),  (0.4, 0.0001), (0.6, 0.0001),  (0.8, 0.0001)] )\n",
    "TrainSettings.set_min_batch_size(1)\n",
    "TrainSettings.set_test_frequency(100)\n",
    "TrainSettings.set_nTest(100000)\n",
    "TrainSettings.set_samplesPerStep(400000)\n",
    "TrainSettings.set_trainingSteps(500)\n",
    "\n",
    "###\n",
    "### 3. Train network and Study results\n",
    "### Comment: For different trainingSetSizes the neural network reset and not saved, hence train and evaluation of yPredicted are done together currently\n",
    "###\n",
    "\n",
    "xTest, yTest, yPredicted = train_and_test(Generator, Regressor, TrainSettings)\n",
    "TrainSettings.set_samplesPerStep(100000)\n",
    "xTest2, yTest2, yPredictedLevel1 = train_and_test(GeneratorLevel1, Regressor, TrainSettings)\n",
    "TrainSettings.set_samplesPerStep(25000)\n",
    "xTest, yTest, yPredictedLevel2 = train_and_test(GeneratorLevel2, Regressor, TrainSettings)\n",
    "TrainSettings.set_samplesPerStep(10000)\n",
    "xTest, yTest, yPredictedLevel3 = train_and_test(GeneratorLevel3, Regressor, TrainSettings)\n",
    "xTest, yTest, yPredictedLevel4 = train_and_test(GeneratorLevel4, Regressor, TrainSettings)\n",
    "multilevel_predicted = {('standard', 100000): np.add(yPredicted[('standard', 100000)], yPredictedLevel1[('standard', 100000)])}\n",
    "multilevel_predicted = {('standard', 100000): np.add(multilevel_predicted[('standard', 100000)], yPredictedLevel2[('standard', 100000)])}\n",
    "multilevel_predicted = {('standard', 100000): np.add(multilevel_predicted[('standard', 100000)], yPredictedLevel3[('standard', 100000)])}\n",
    "multilevel_predicted = {('standard', 100000): np.add(multilevel_predicted[('standard', 100000)], yPredictedLevel4[('standard', 100000)])}\n",
    "plot_results(\"predicted vs. expected\", multilevel_predicted, xTest, yTest, Generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83a8566224840326395a21c083192bd4c5adbde2ed4f12bcb51b671fb460c3a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
