{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open this notebook in colab\n",
    "#<a href=\"https://colab.research.google.com/github/da-roth/NeuronalNetworkTensorflowFramework/blob/main/src/Examples_Colab/MonteCarloLearning/Implementation_Multilevel_POC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install git+https://github.com/da-roth/NeuronalNetworkTensorflowFramework#montecarlolearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### 0. Import packages and references\n",
    "###\n",
    "### - dataSeed = seed for simulations or (for csv input) for randomization of csv\n",
    "\n",
    "from montecarlolearning import *\n",
    "\n",
    "###\n",
    "### 1. Set Generator: Single-level with Euler-Maruyama and h = 2^(-4) step-width\t\n",
    "###\n",
    "Generator = Multilevel_GBM(Multilevel_Train_Case.Euler, 4)\n",
    "Generator.set_inputName('S')\n",
    "Generator.set_outputName('EuropeanCallPrice(S)')\n",
    "\n",
    "###\n",
    "### 2. Set Nueral network structure / \n",
    "# Hyperparameters\n",
    "### \n",
    "\n",
    "Regressor = Neural_Approximator()\n",
    "Regressor.set_Generator(Generator)\n",
    "Regressor.set_hiddenNeurons(20)\n",
    "Regressor.set_hiddenLayers(2)\n",
    "Regressor.set_activationFunctionsHidden(tf.nn.sigmoid)\n",
    "Regressor.set_activationFunctionOutput(tf.nn.sigmoid)\n",
    "Regressor.set_weight_seed(1)\n",
    "\n",
    "TrainSettings = TrainingSettings()\n",
    "TrainSettings.useExponentialDecay(0.01, 0.1, 1000)\n",
    "TrainSettings.set_min_batch_size(1)\n",
    "TrainSettings.set_test_frequency(500)\n",
    "TrainSettings.set_nTest(10000)\n",
    "TrainSettings.set_samplesPerStep(10000)\n",
    "TrainSettings.set_trainingSteps(1000)\n",
    "\n",
    "###\n",
    "### 3. Train network and Study results\n",
    "### Comment: For different trainingSetSizes the neural network reset and not saved, hence train and evaluation of yPredicted are done together currently\n",
    "###\n",
    "\n",
    "xTest, yTest, yPredicted = train_and_test(Generator, Regressor, TrainSettings)\n",
    "plot_results(\"predicted vs. expected\", yPredicted, xTest, yTest, Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Multi-level Monte Carlo Learning \n",
    "###\n",
    "\n",
    "# Train level 0 with Milstein and h = 2^(0) step-width\n",
    "Generator = Multilevel_GBM(Multilevel_Train_Case.Milstein, 0)\n",
    "Generator.set_inputName('S')\n",
    "Generator.set_outputName('MultiLevelApproximation')\n",
    "# Train level 1 (level estimator) with Milstein and h_fine = 2^(-1) and h_coarse = 2^(0)\n",
    "GeneratorLevel1 = Multilevel_GBM(Multilevel_Train_Case.LevelEstimator, 0)\n",
    "GeneratorLevel1 .set_inputName('x')\n",
    "GeneratorLevel1 .set_outputName('P_1-P_0')\n",
    "# Train level 2 (level estimator) with Milstein and h_fine = 2^(-2) and h_coarse = 2^(-1)\n",
    "GeneratorLevel2 = Multilevel_GBM(Multilevel_Train_Case.LevelEstimator, 1)\n",
    "GeneratorLevel2 .set_inputName('x')\n",
    "GeneratorLevel2 .set_outputName('P_2-P_1')\n",
    "# Train level 3 (level estimator) with Milstein and h_fine = 2^(-3) and h_coarse = 2^(-2)\n",
    "GeneratorLevel3 = Multilevel_GBM(Multilevel_Train_Case.LevelEstimator, 2)\n",
    "GeneratorLevel3 .set_inputName('x')\n",
    "GeneratorLevel3 .set_outputName('P_3-P_2')\n",
    "# Train level 4 (level estimator) with Milstein and h_fine = 2^(-4) and h_coarse = 2^(-3)\n",
    "GeneratorLevel4 = Multilevel_GBM(Multilevel_Train_Case.LevelEstimator, 3)\n",
    "GeneratorLevel4 .set_inputName('x')\n",
    "GeneratorLevel4 .set_outputName('P_4-P_3')\n",
    "\n",
    "\n",
    "###\n",
    "### 2. Set Nueral network structure / Hyperparameters\n",
    "### \n",
    "\n",
    "Regressor = Neural_Approximator()\n",
    "Regressor.set_Generator(Generator)\n",
    "Regressor.set_hiddenNeurons(20)\n",
    "Regressor.set_hiddenLayers(2)\n",
    "Regressor.set_activationFunctionsHidden(tf.nn.sigmoid)\n",
    "Regressor.set_activationFunctionOutput(tf.nn.sigmoid)\n",
    "Regressor.set_weight_seed(1)\n",
    "\n",
    "TrainSettings = TrainingSettings()\n",
    "TrainSettings.useExponentialDecay(0.01, 0.1, 1000)\n",
    "TrainSettings.set_min_batch_size(1)\n",
    "TrainSettings.set_test_frequency(500)\n",
    "TrainSettings.set_nTest(10000)\n",
    "TrainSettings.set_samplesPerStep(40000)\n",
    "TrainSettings.set_trainingSteps(1000)\n",
    "\n",
    "###\n",
    "### 3. Train and test\n",
    "### Comment: For different trainingSetSizes the neural network reset and not saved, hence train and evaluation of yPredicted are done together currently\n",
    "###\n",
    "\n",
    "xTest, yTest, yPredicted = train_and_test(Generator, Regressor, TrainSettings)\n",
    "TrainSettings.set_samplesPerStep(10000)\n",
    "TrainSettings.useExponentialDecay(0.01, 0.1, 500)\n",
    "xTest2, yTest2, yPredictedLevel1 = train_and_test(GeneratorLevel1, Regressor, TrainSettings)\n",
    "TrainSettings.set_samplesPerStep(10000)\n",
    "xTest, yTest, yPredictedLevel2 = train_and_test(GeneratorLevel2, Regressor, TrainSettings)\n",
    "TrainSettings.set_samplesPerStep(10000)\n",
    "xTest, yTest, yPredictedLevel3 = train_and_test(GeneratorLevel3, Regressor, TrainSettings)\n",
    "xTest, yTest, yPredictedLevel4 = train_and_test(GeneratorLevel4, Regressor, TrainSettings)\n",
    "\n",
    "# Add all levels for test data\n",
    "multilevel_predicted = {('standard', 10000): np.add(yPredicted[('standard', 10000)], yPredictedLevel1[('standard', 10000)])}\n",
    "multilevel_predicted = {('standard', 10000): np.add(multilevel_predicted[('standard', 10000)], yPredictedLevel2[('standard', 10000)])}\n",
    "multilevel_predicted = {('standard', 10000): np.add(multilevel_predicted[('standard', 10000)], yPredictedLevel3[('standard', 10000)])}\n",
    "multilevel_predicted = {('standard', 10000): np.add(multilevel_predicted[('standard', 10000)], yPredictedLevel4[('standard', 10000)])}\n",
    "\n",
    "# Plot P_0 + [P_1-P_0] + [P_2-P_1] + [P_3-P_2] + [P_4-P_3]\n",
    "plot_results(\"predicted vs. expected\", multilevel_predicted, xTest, yTest, Generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f469d54171fe07f2f0be32f89b0b6a9254e5e5358f5513dbb28f03e97b475cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
